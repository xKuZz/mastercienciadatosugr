---
title: "EDA1"
author: "David Criado Ramón"
date: "7/11/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("dplyr")
library("ggplot2")
library("car")
```

# 1. Exploratory Data Analysis.
## a. Ejemplo 1, hip dataset.

### Descárgate el dataset hip con el siguiente comando:
```{r}
hip <- read.table("http://astrostatistics.psu.edu/datasets/HIP_star.dat",
                  header=T, fill=T)
```

### Una vez descargado, comprueba la dimensión y los nombres de las columnas del dataset. ¿Qué dimensión tiene? ¿qué tipos de datos alberga?
```{r}
dim(hip)
```

```{r}
sapply(hip, class)
```
El dataset contiene 2719 muestras y tiene 9 atributos. Todos los datos son de tipo numérico, con 8 de los atributos números reales (variables continuas) y uno de ellos, HIP, son números enteros (variable discreta).

```{r}
head(hip)
```
### Muestra por pantalla la columna de la variable RA.
Sólo voy a mostrar los 100 primeros elementos de la columna, para que no ocupe demasiado espacio en el PDF.
```{r}
head(hip$RA, n=100)
```
### Calcula las tendencias centrales de todos los datos del dataset (mean, mediana) utilizando la function apply.

```{r}
print("Medias")
sapply(hip, mean, na.rm=T)
```

```{r}
print("Medianas")
sapply(hip, median, na.rm=T)
```

### Haz lo mismo para las medidas de dispersión mínimo y máximo. ¿Sería posible hacerlo con un único comando? ¿Qué hace la función range()?

```{r}
print("Mínimos")
sapply(hip, min, na.rm=T)
```

```{r}
print("Máximos")
sapply(hip, max, na.rm=T)
```

Sí, mediante la función **range**, que nos devuelve un vector conteniendo los mínimos (primer elemento de cada vector) y los máximos (segundo elemento de cada vector).

```{r}
print("Mínimos y máximos")
sapply(hip, range, na.rm=T)
```

### Sin embargo, las medidas más populares de dispersión son la varianza (var()), su desviación estándar (sd()) y la desviación absoluta de la mediana o MAD. Calcula estas medidas para los valores de RA.
```{r}
print("Varianza, Desviación estándar, Desviación absoluta de la mediana")
c(var(hip$RA, na.rm=T), sd(hip$RA, na.rm=T), mad(hip$RA, na.rm=T))
```


### Imagina que quieres calcular dos valores de una sóla vez. ¿Te serviría este código?
```{r}
f = function(x) c(median(x), mad(x))  
f(hip[,3])

```
Sí que sirve. El código encapsula la llamada a las funciones y nos permite aplicar ambas a un vector o una columna de un data frame. Podría ser problemática si tenemos "missing values" pues no se ha indicado que se ignoren dichos valores.

### ¿Cuál sería el resultado de aplicar apply(hip,2,f)?
```{r}
apply(hip, 2, f)
```

Sería el resultado de aplicar la mediana y la desviación absoluta de la mediana a cada columna. Nótese que puesto que había "missing values" en el atributo B.V aparece NA como resultado de estas operaciones.

### Vamos a medir la dispersión de la muestra utilizando el concepto de cuartiles. El percentil 90 es aquel dato que excede en un 10% a todos los demás datos. El cuartil (quantile) es el mismo concepto, solo que habla de proporciones en vez de porcentajes. De forma que el percentil 90 es lo mismo que el cuartil 0.90. La mediana “median” de un dataset es el valor más central, en otras palabras exactamente la mitad del dataset excede la media. Calcula el cuartil .10 y .50 para la columna RA del dataset hip. Sugerencia: quantile()

```{r}
quantile(hip$RA, c(0.1, 0.5))
```

### Los cuantiles 0.25 y 0.75 se conocen como el  first quartile y el third quartile, respectivamente. Calcula los cuatro cuartiles para RA con un único comando.

```{r}
quantile(hip$RA)
```

### Otra medida de dispersion es la diferencia entre el primer y el tercer cuartil conocida como rango intercuartil (IQR) Inter Quantile Range. ¿Obtienes ese valor con la función summary()?

```{r}
summary(hip)
```
No obtenemos esa información directamente pero si que tenemos el valor del primer y tercer cuartil, por lo que podemos restar el tercer con el primer cuartil para obtener el IQR.

### Hasta ahora has ignorado la presencia de  valores perdidos NA. La función any() devuelve TRUE si se encuentra al menos un TRUE en el vector que damos como argumento. Su combinación con is.na es muy útil. ¿qué obtienes cuando ejecutas el siguiente comando? ¿Cómo lo interpretas?

```{r}
hasNA = function(x) any(is.na(x)) 
apply(hip,2,hasNA)
```
Al aplicar el comando la función hasNA es aplicada a cada columna, por lo que la salida nos indicará los nombre de las columnas y pondrá TRUE en aquellas que contengan "missing values" y false en el resto.

### Prueba a ejecutar el siguiente comando.
```{r}
min(hip$B.V)
```
Nos devuelve NA, porque existen "missing values" en la columna, hemos de indicar na.rm=T para que los ignore.
 
### hip1 = na.omit(hip) Como has observado  nos devuelve NA para toda la columna,  normalmente querríamos poder usar la función sobre el resto de datos que no son NA: Para ello podemos utilizar la función na.omit. ¿Que ocurre cuando lo hacemos?. Usando apply calcula la media para hip. Intenta calcular la media de forma que solo cambie la de B.V cuando ignores los valores NA
```{r}
apply(hip, 2, mean)
```


```{r}
hip1 = na.omit(hip)
apply(hip1, 2, mean)
```

Al haber aplicado na.omit se eliminan las muestras que contienen na, por lo que el valor de la media de B.V ahora va a ser numérico en vez de NA.

### Obtén una idea aproximada de tus datos mediante la creación de un boxplot del hip dataset.

```{r}
boxplot(hip)
```

Podemos observar que HIP tiene una escala muy distinta del resto de variables y pmRA y pmDE tienen una cantidad abundante de "outliers".

### Crea un scatterplot que te compare los valores de RA y DE. Representa los puntos con el símbolo ‘.’ Y que estos puntos sean de color rojo si DE excede de 0. Sugerencia: ifelse()

Vamos a representar de verde los puntos que tengan DE <=0 y de rojo los puntos que tenga DE > 0. 

```{r}
ggplot(hip, aes(x=RA, y=DE)) + 
  geom_point(col=ifelse(hip$DE > 0, "red", "green"))
```

### Haz un scatterplot de RA y pmRA. ¿Ves algún patrón?
```{r}
ggplot(hip, aes(x=RA, y=pmRA)) + geom_point(col="green")
```
Parece que los puntos siguen una parábola. Observémoslo trazando una con geom_smooth.

```{r}
ggplot(hip, aes(x=RA, y=pmRA)) + geom_point(col="green") +
  geom_smooth(method=lm, formula = y ~ x + I(x^2))
```

Parece que la distribución de los puntos sigue la trayectoria de la parábola trazada, pero hay presentes un número considerable de "outliers".

### En vez de crear los plots por separado para cada par de columnas, hazlos con un solo comando con el scatterplot matrix.
```{r}
scatterplotMatrix(hip)
```
No se ve mucho en el PDF de este scatterplox hay demasiadas variables, si desea analizarlo es mejor visualizarlo en R y hacer zoom, probablemente para mostrarlo en un informe es necesario reducir el número de datos a comparar de forma simultánea.

### Para poder acceder a las variables por su nombre usa attach(hip).Vamos a seleccionar las estrellas Hyadas del dataset aplicando los siguientes filtros:

-	RA in the range (50,100) 
-	DE in the range (0,25) 
-	pmRA in the range (90,130) 
-	pmDE in the range (-60,-10) 
-	e_Plx <5 
-	Vmag >4 OR B.V <0.2 (this eliminates 4 red giants) 

Voy a hacerlo en el siguiente ejercicio utilizando *dply* y sin usar *attach*

### Crea un nuevo dataset con la aplicación de estos filtro. El Nuevo dataset se llama hyades. ¿Que dimensiones tiene? Grafica un scatterplot de Vmag vs B.V

```{r}
hyades <- hip %>% filter(between(RA,50,100) &
                  between(DE, 0, 25) &
                  between(pmRA, 90, 130) &
                  between(pmDE, -60, -10) &
                  e_Plx < 5 &
                  (Vmag > 4 | B.V < 0.2))
dim(hyades)
```
El nuevo dataset tiene 88 muestras y 9 atributos para cada muestra.

```{r}
ggplot(hyades, aes(x=Vmag, y=B.V)) + geom_point(col="green")
```
En este caso parece que ambas variables siguen una relación lineal, utilicemos geom_smooth para observarlo con la recta.

```{r}
ggplot(hyades, aes(x=Vmag, y=B.V)) + geom_point(col="green") +
       geom_smooth(method="lm")
```

## b. Ejemplo 2, iris dataset.

Vamos a utilizar el ejemplo del dataset iris que está incluido en la distribución de R. Este dataset fue creado por Douglas Fisher.  Consta de tres clases y tipos de 3 clases de tipos de flores: _setosa_, _virginica_ y _versicolor_. Cada una de ellas con cuatro atributos: _sepal width_, _sepal length_, _petal width_, _petal length_.

### Inspecciona las primeras filas del dataset y calcula el summary() del mismo con cada atributo del dataset.
```{r}
head(iris)
```
```{r}
summary(iris)
```

### Crea un histograma de _petal.width_, teniendo en cuenta que el número de _bins_ es variable fija éste a 9. Añádele color y nombres al eje x _"Petal Width"_ y al gráfico dale el nombre _"Histogram of Petal Width"_. Crea un histograma para cada variable.
- Petal Width

_Nota personal: Por alguna razón, poner xlab dentro de labs no me cambia el título del eje X, así que lo pongo fuera._

```{r}
ggplot(iris, aes(x=Petal.Width)) + 
  geom_histogram(bins = 9, fill="blue", col="black") +
  labs(title="Histogram of Petal Width") + xlab("Petal Width")

```

- Petal Length
```{r}
ggplot(iris, aes(x=Petal.Length)) + 
  geom_histogram(bins = 9, fill="blue", col="black") +
  labs(title="Histogram of Petal Length") + xlab("Petal Length")
```

- Sepal Width

```{r}
ggplot(iris, aes(x=Sepal.Width)) + 
  geom_histogram(bins = 9, fill="blue", col="black") +
  labs(title="Histogram of Sepal Width") + xlab("Sepal Width")
```

- Sepal Length

```{r}
ggplot(iris, aes(x=Sepal.Length)) + 
  geom_histogram(bins = 9, fill="blue", col="black") +
  labs(title="Histogram of Sepal Length") + xlab("Sepal Length")
```

### Crea los cuartiles del dataset.

```{r}
# No tomamos la especie para los cuartiles.
apply(iris[,1:4], 2, quantile)
```

### Representa en un boxplot la variable ancho de hoja dependiendo del tipo de hoja que tengan.

```{r}
ggplot(iris, aes(x=Species, y=Petal.Width)) + geom_boxplot()
```
  
### Crea los cuartiles para cada tipo de iris y represéntalos en un plot como líneas cada una de un color
```{r}
df_setosa <- subset(iris[-5], iris$Species=="setosa")
df_versicolor <- subset(iris[-5], iris$Species=="versicolor")
df_virginica <- subset(iris[-5], iris$Species=="virginica")
q_setosa <- apply(df_setosa, 2, quantile)
q_versicolor <- apply(df_versicolor, 2, quantile)
q_virginica <- apply(df_virginica, 2, quantile)
colnames(q_setosa) <- paste0(colnames(q_setosa), ".Setosa")
colnames(q_versicolor) <- paste0(colnames(q_versicolor), ".Versicolor")
colnames(q_virginica) <- paste0(colnames(q_virginica), ".Virginica")
df_quantiles_iris <- as.data.frame(cbind(q_setosa, q_versicolor, q_virginica))
df_quantiles_iris$Percentil <- seq(0,100,25)
df_quantiles_iris
```
```{r}
library(reshape2)
# Utilizo melt de reshape2 para facilitar pintar muchos gráficos de líneas.
df_quantiles_iris2 <- melt(df_quantiles_iris, id.var="Percentil")
names(df_quantiles_iris2) <-c("Percentil", "Variable", "Valor")

ggplot(df_quantiles_iris2, aes(x=Percentil, y=Valor, colour=Variable)) +
  geom_line()
```

### Crea los boxplot de la longitud del pétalo en función de la especie de Iris.
```{r}
ggplot(iris, aes(x=Species, y=Petal.Length)) + geom_boxplot()
```

### Compara con scatter plots las variables entre sí.
```{r}
scatterplotMatrix(iris[-5])
```

### Crea una nueva columna llamada proporción que es el ratio entre Sepal.Length y Sepal.Width. Podeis hacerlo en R base o usando el paquete dplyr. Los que no lo conozcan tienen información al final del documento.
```{r}
iris %>% mutate(proporcion=Sepal.Length/Sepal.Width)
```


## El conjunto de datos “swiss” contiene una medida estandarizada de fecundidad y varios indicadores socioeconómicos para cada una de las 47 provincias francófonas de Suiza. 
```{r}
swiss
```


### ¿Qué diagrama dibujaría para mostrar la distribución de todos los valores? ¿Qué conclusiones sacarías? 
Podríamos utiliza un histograma, pero puesto que el número de muestras es relativamente bajo (47 muestras), vamos a optar por pintar una curva de densidad de distribución.
```{r}
ggplot(swiss, aes(x=Fertility)) + geom_density()
ggplot(swiss, aes(x=Agriculture)) + geom_density()
ggplot(swiss, aes(x=Examination)) + geom_density()
ggplot(swiss, aes(x=Education)) + geom_density()
ggplot(swiss, aes(x=Catholic)) + geom_density()
ggplot(swiss, aes(x=Infant.Mortality)) + geom_density()
```

Las variables Fertility, Agriculture e Infant Mortality son "negative skewed". Las distribuciones de Fertility e Infant Mortality se asemejan basante. Examination es "positive skewed". Education y Catholic son multimodales, lo que nos podría indicar la presencia de varias clases. En concreto, Catholic tiene 3 puntos extremos bastante definidos, mientras que en Education no queda tan claro.

### Dibuje gráficos para cada variable. ¿Qué puede concluir de las distribuciones con respecto a su forma y posibles valores atípicos? 
Hemos hablado brevemente de la forma en el apartado anterior, para ver la escala y los posibles valores atípicos vamos a usar un boxplot.

```{r}
boxplot(swiss)
```
Podemos ver que todas las variables se encuentran dentro del rango [0, 100], presentan diferentes escalas pero son comparables en el boxplot. La variable con más variabilidad en los datos es educación donde la mayoría de los datos se encuentran alrededor del 10 pero encontramos posibles "outliers" en "Education". Por otro lado, sólo vemos dos "outliers" en Fertility y uno en "Infant.Mortality".

### Dibuja un diagrama de dispersión de Fertilidad frente a % Catholic. ¿Qué tipo de áreas tienen las tasas de fertilidad más bajas? 

```{r}
ggplot(swiss, aes(x=Fertility, y=Catholic)) + geom_point()
```

Las zonas menos fértiles se corresponde a aquellas donde alrededor la mitad de la población es católica, aunque sólo tenemos 3 muestras. Estas van seguidas de las zonas donde la población católica es inferior al 25 %.


### ¿Qué tipo de relación existe entre las variables Educación y Agricultura?

```{r}
ggplot(swiss, aes(x=Education, y=Agriculture)) + geom_point()
```
La tendencia es que a menor nivel de educación, más porcentaje de hombres trabajando en la agricultura.

## El conjunto de datos de aceites de oliva es bien conocido y se puede encontrar en varios paquetes, por ejemplo, como aceitunas en extracat.. La fuente original de los datos es el artículo [Forina et al., 1983].
El paquete extracat ha sido eliminado de CRAN así que voy a usar otro paquete que contiene el dataset
```{r}
library("classifly")
olives
```

### Dibuje un scatterplot  de las ocho variables continuas. ¿Cuáles de los ácidos grasos están fuertemente asociados positivamente y cuáles fuertemente asociados negativamente? 
```{r}
scatterplotMatrix(olives[,3:length(olives)])
```
- Tienen una relación líneal fuerte positiva palmitic con palmitoleic, tienen una relación lineal fuerte negativa palmitic con oleic y oleic con linoleic.

### ¿Hay valores atípicos u otras características que valga la pena mencionar?
```{r}
boxplot(olives)
```
```{r}
boxplot(olives[-6])
```
Vemos que hay bastantes outliers en stearic, linoleic y arachidic.

## El conjunto de datos se llama Lanza del paquete HSAUR2

```{r}
library("HSAUR2")
Lanza
```

### Se informan los datos de cuatro estudios. Dibuje un diagrama para mostrar si los cuatro estudios son igualmente grandes. 
```{r}
ggplot(Lanza, aes(x=study)) + geom_bar()
```

Tenemos un número bastante similar de muestras en los tres primeros estudios pero muchos menos en el último.

### El resultado se mide por la clasificación de la variable con puntuaciones de 1 (mejor) a 5 (peor). ¿Cómo describirías la distribución?
```{r}
ggplot(Lanza, aes(classification)) + geom_bar()
```
Vemos que tenemos muchas más muestras con classification 1 que del resto (más de 70 muestras), viene seguida por las de classification 5 (más de 40 muestras), a continuación de 3 (35-36 muestras) y para finalizar 2 y 4 (entre 20-25). Dado el número de muestra es claro que existen demasiadas muestras de la clase 1 con respecto al resto, 2 y 4 son muy parecidas e incluso podríamos considerar que 3 está dentro de un margen razonable. Estamos ante un caso de clases desbalanceadas.

## El paquete vcdExtra incluye datos de un viejo estudio de cáncer de mama sobre la supervivencia o muerte de 474 pacientes. 
```{r}
library("vcdExtra")
```


### Convierta los datos en un data frame y dibuje gráficos para comparar las tasas de supervivencia, primero, por grado de malignidad y, en segundo lugar, por centro de diagnóstico. 
```{r}
df_cancer <- as.data.frame(Cancer)
df_cancer1 <- df_cancer %>% group_by(Survival, Grade) %>% summarize(Freq=sum(Freq))
df_cancer2 <- df_cancer %>% group_by(Survival, Center) %>% summarize(Freq=sum(Freq))
ggplot(df_cancer1, aes(x=Survival, y=Freq, group=Grade, fill=Grade)) +
  geom_bar(stat="identity", position="dodge")

ggplot(df_cancer2, aes(x=Survival, y=Freq, group=Center, fill=Center)) +
  geom_bar(stat="identity", position="dodge")
  
```


### ¿Qué diagrama dibujaría para comparar las tasas de supervivencia tanto por grado de malignidad como por centro de diagnóstico? ¿Importa el orden de las variables explicativas?
El diagrama presentado en el apartado anterior es suficientemente explicativo para comparar ambas variables. Lo importante del orden de esas variables es que no implique una mala legibilidad del gráfico.

## Dataset crabs (del paquete MASS) [Venables y Ripley, 2002]. Los autores inicialmente se transforman a una escala logarítmica y luego escriben que:

 “The data are very highly correlated and scatterplot matrices and brush plots [i.e. interactive graphics] are none too revealing.”. 

```{r}
library("MASS")
scatterplotMatrix(crabs[,3:length(crabs)])
```

### Utilizando gráficos generales, comente si la transformación logaritmica fue una buena idea y si está de acuerdo con su afirmación sobre las correlaciones.
La necesidad de una transformación logarítmica es un indicativo de que queremos reducir una "skweness" positiva, sin embargo, a vista de las curvas de densidad (presentes en la diagonal principal) no vemos ninguna que sea considerablemente asimétricra, dejando una cola más larga hacia la derecha (asimetría positiva).


## Extra 2. Cómo crear subgrupos de datos en R

### Busca información sobre la function cut(). Para ilustrar su uso vamos a utilizar el dataset state.x77. Si no lo tienes instalado instala el paquete R-Datasets. Usa la función head() para ver como son tus datos.

-	Extrae la columna Frost y asigna el resultado a la variable frost
```{r}
frost <- as.data.frame(state.x77)$Frost
```

-	Tu Nuevo objeto es un vector numérico
```{r}
class(frost)
```

-	Ahora intenta agrupar los datos en frost en tres niveles. Para crear bins en tus datos puedes utilizar la función cut(). 
```{r}
cut(frost, 3)
```


-	¿Que obtienes como nombres de los niveles?
Obtengo como nombres el intervalo que representa el rango de valores para cada uno de los niveles.

-	En la realidad no existen estados que tengan frost en días negativos. Esto es porque R añade un poco de padding. Prueba a solucionar el problema utilizando el parámetro include.lowest=TRUE en cut()
```{r}
cut(frost, 3, include.lowest=TRUE)
```
No conseguimos arregarlo con include.lowest. Sólo ha cambiado el intervalo de abierto a cerrado.

-	Los nombres de los niveles no son demasiado informativos, especifica nuevos nombres para los niveles.
```{r}
frost <- cut(frost, 3, include.lowest=TRUE, labels=c("Bajo", "Medio", "Alto"))
```

-	Después de este paso has creado un factor que clasifica los estados en bajo, medio y alto según el numero de heladas.
```{r}
frost
```

-	Ahora cuenta el número de estados que  hay en cada uno de los niveles. PISTA: utiliza la función table()

```{r}
table(frost)
```


## Extra 3. Cómo ordenar tablas (dplyr)
```{r}
library("dslabs")
library("tidyverse")
```

### Utiizando el paquete dplyr realiza el siguiente análisis sobre el dataset murders. Para aquellos que no hicieron el curso de inicio a la programación para Ciencia de Datos he puesto en PRADO unas diapositivas explicando el funcionamiento.

```{r}
murders
```

-	Averigua cual es el estado con la mayor población
```{r}
murders %>% filter(population==max(population))
```

-	Averigua cual es el estado con el mayor ratio de asesinatos
```{r}
murders %>% mutate(ratio=total/population) %>%
            filter(ratio==max(ratio))
```

-	Averigua cual es el estado con el menor ratio de asesinatos
```{r}
murders %>% mutate(ratio=total/population) %>%
            filter(ratio==min(ratio))
```

-	Crea una tabla ordenada alfabeticamente por region y por el ratio de asesinatos 
```{r}
murders %>% mutate(ratio=total/population) %>%
            arrange(region, ratio)
```

-	Crea una tabla con la media del ratio de asesinatos por region
```{r}
murders %>% mutate(ratio=total/population) %>% 
            group_by(region) %>%
            summarize(mean(ratio))
```

